{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CubicOneShotSGD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNbBbqwrienrzV21Ps1D8CB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeligism/CubicOneShotSGD/blob/main/CubicOneShotSGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkmUPE57u1F2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optimizer\n",
        "import torch.utils.data as data_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download datasets\n",
        "A9A_DATASET = \"a9a.txt\"\n",
        "!wget -O \"{A9A_DATASET}\" \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a9a\""
      ],
      "metadata": {
        "id": "BkEgTuB4ubfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Args"
      ],
      "metadata": {
        "id": "1-ZG6h3t6bKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "    self.feature_dim = 124\n",
        "    self.output_dim = 2\n",
        "    self.dataset = \"a9a\"\n",
        "    self.device = \"cuda:0\"\n",
        "    self.num_models = 10\n",
        "    self.num_iters = 100\n",
        "    self.base_lr = 1e-3\n",
        "    self.batch_size = 1\n",
        "\n",
        "args = Args()"
      ],
      "metadata": {
        "id": "9uc_nfMYvf0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "XhRSvF356eCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_svmlight_file\n",
        "\n",
        "class MyDataset(data_utils.Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.data = None\n",
        "        self.labels = None\n",
        "\n",
        "        if self.dataset in (\"a9a\",):\n",
        "            with open(A9A_DATASET, \"r\") as f:\n",
        "                X, y = load_svmlight_file(f)\n",
        "                self.data = torch.Tensor(X). # NxX\n",
        "                self.labels = torch.Tensor(y).unsqueeze(1)  # NxY\n",
        "        else:\n",
        "            raise Exception(f\"Dataset '{self.dataset}' not found.\")\n",
        "\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n"
      ],
      "metadata": {
        "id": "KO663xAfq-p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "20qUSO6P6fkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LocalSGD(torch.optim.SGD):\n",
        "    def aggregate(self):\n",
        "        num_models = len(self.param_groups)\n",
        "        num_params = len(self.param_groups[model_idx][\"params\"])\n",
        "        aggregated_params = [None] * num_params\n",
        "        # Average models (no_grad?)\n",
        "        for param_idx in range(num_params):\n",
        "            param_list = [self.param_groups[model_idx][\"params\"][param_idx].data\n",
        "                          for model_idx in range(num_models)]\n",
        "            aggregated_params[param_idx] = torch.mean(torch.stack(param_list))\n",
        "        # Synchronize\n",
        "        for model_idx in range(num_models):\n",
        "            for param_idx in range(num_params):\n",
        "                self.param_groups[model_idx][\"params\"][param_idx] = aggregated_params[param_idx]"
      ],
      "metadata": {
        "id": "QYIsRRlUreDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregation Schedule"
      ],
      "metadata": {
        "id": "IkyT6KIE60X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The schedule is just the iterations in which we aggregate\n",
        "# For one shot averaging, we average on the last iteration\n",
        "aggregation_idxs = set(self.num_iters-1)"
      ],
      "metadata": {
        "id": "9leOIBxH6299"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "Qlp2pd1O6hRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_idx):\n",
        "    return nn.Linear(args.feature_dim, args.output_dim)"
      ],
      "metadata": {
        "id": "M2bu9BPj6Zkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "kTLUvV-S6if-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train prep"
      ],
      "metadata": {
        "id": "iLyNaI6y6kha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MyDataset(args.dataset)\n",
        "dataloader = data_utils.DataLoader(dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True)\n",
        "data_sampler = iter(dataloader)\n",
        "def sample_dataset():\n",
        "    try:\n",
        "        x, y = next(data_sampler)\n",
        "    except StopIteration:\n",
        "        data_sampler = iter(dataloader)\n",
        "        x, y = next(data_sampler)\n",
        "    return x, y\n",
        "\n",
        "models = [create_model(i).to(device=args.device) for i in range(args.num_models)]\n",
        "\n",
        "param_groups = [{\"params\": models[i].parameters(), lr=lrs[i]} for i in range(args.num_models)]\n",
        "optimizer = LocalSGD(param_groups, lr=args.base_lr)\n",
        "loss_fn = nn.MSELoss().to(device=args.device)"
      ],
      "metadata": {
        "id": "b2auF1D-vm6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(args.num_iters):\n",
        "    if t in aggregation_idxs:\n",
        "        optimizer.aggregate()\n",
        "    else:\n",
        "        for model in models:\n",
        "            x, y = sample_dataset()\n",
        "            x = x.to(device=args.device)\n",
        "            y = y.to(device=args.device)\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()"
      ],
      "metadata": {
        "id": "pJaOYD5m7t7W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}